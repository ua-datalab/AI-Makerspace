{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d716f5fb",
   "metadata": {},
   "source": [
    "# AI Makerspace Session 3\n",
    "## Title: Running OLLAMA on HPC\n",
    "_Hosted by:_ Mithun Paul\n",
    "_Date:_ 10/18/24\n",
    "\n",
    "\n",
    "steps\n",
    "- Run Ollama on laptop\n",
    "- how to connect to HPC\n",
    "- how to install ollama on HPC\n",
    "\n",
    "- Run Ollama on Laptop\n",
    "# # What is Ollama\n",
    "\n",
    "- (Omni-Layer Learning Language Acquisition Model)\n",
    "- Refer earlier [lecture](https://github.com/ua-datalab/Generative-AI/wiki/Running-LLM-Locally:-Ollama) from other workshop.\n",
    "\n",
    "\n",
    "### for osx -after downloading in OSX, move to applications folder, double click to start, then in a fresh terminal type\n",
    "`ollama run llama3.2`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4296ea-8546-4b02-9963-88ea44744464",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf4c4aa6-14f0-4def-8c55-1053426f1874",
   "metadata": {},
   "source": [
    "### Connecting to HPC\n",
    "- [OOD](https://ood.hpc.arizona.edu/pun/sys/dashboard)\n",
    "- SSH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482928db-5ba8-4ae9-952d-fcf7147023de",
   "metadata": {},
   "source": [
    "# SSH commands to connect to HPC- \n",
    "\n",
    "- `ssh mithunpaul@hpc.arizona.edu`\n",
    "        - this connects to Login node (to know what login node and bastion node is refer HPC [docs](https://hpcdocs.hpc.arizona.edu/quick_start/logging_in/#system-access)\n",
    "\n",
    "now to connect to Bastion hosts (wentletrap and junonia)type\n",
    "- `shell`\n",
    "  \n",
    "Then switch to elGato (easier access)\n",
    "\n",
    "- `elgato`\n",
    "- `tmux`\n",
    "\n",
    "COmmands to install [Ollama](https://github.com/ollama/ollama/blob/main/docs/linux.md#manual-install)\n",
    "\n",
    "- `curl -L https://ollama.com/download/ollama-linux-amd64.tgz -o ollama-linux-amd64.tgz`\n",
    "- `tar -zxvf ollama-linux-amd64.tgz`\n",
    "-  `./bin/ollama serve`\n",
    "\n",
    "  Switch out from that tmux window, or connect through another sessionto HPC\n",
    "  - from the other tmux window run\n",
    "  -  `./bin/ollama run llama3.2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2c5bd5-8c96-410e-9afc-9f7273ddf04f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
